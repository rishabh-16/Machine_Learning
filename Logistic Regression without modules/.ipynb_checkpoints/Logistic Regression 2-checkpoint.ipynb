{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.loadtxt(open(\"C:\\\\Users\\\\Rishabh\\\\Desktop\\\\Machine Learning\\\\Logistic Regression\\\\LogisticRegressionData2.txt\"),delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking 70% as training data and rest 30% as test data\n",
    "[a,b]=np.shape(data)\n",
    "X_train=data[0:(10*a)//10,0:b-1]\n",
    "y_train=data[0:(10*a)//10,b-1:b]\n",
    "X_test=data[0:a,0:b-1]\n",
    "y_test=data[0:a,b-1:b]\n",
    "\n",
    "Xt=X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    mean=np.mean(X,axis=0)\n",
    "    dev=np.std(X,axis=0)\n",
    "    Xn=(X-mean)/dev\n",
    "    return Xn,mean,dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=len(y_train)\n",
    "[X_train,mean,dev]=normalize(X_train)\n",
    "X_train=np.hstack((np.ones((m,1)),X_train))\n",
    "n=np.shape(X_train)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13119437]\n",
      " [0.01181777]\n",
      " [0.2306109 ]]\n"
     ]
    }
   ],
   "source": [
    "#initialising theta\n",
    "n=np.shape(X_train)[1]\n",
    "theta=np.random.random((n,1))\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations=1500\n",
    "alpha=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    ans=1/(1+np.exp(-z))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcost(X,y,theta):\n",
    "    m=len(y)\n",
    "    pred=sigmoid(X.dot(theta))\n",
    "    J=(1/m) * (-y.T.dot(np.log(pred))-(1-y).T.dot(np.log(1-pred)))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial cost = [[0.70271054]]\n"
     ]
    }
   ],
   "source": [
    "cost=calcost(X_train,y_train,theta)\n",
    "print(\"initial cost =\", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X,y,theta,alpha,noi):\n",
    "    m=len(y)\n",
    "    for i in range(noi):\n",
    "        pred=sigmoid(X.dot(theta))\n",
    "        theta = theta - (alpha/m)*(X.T.dot(pred-y))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03413064]\n",
      " [-0.15010481]\n",
      " [-0.00938385]]\n"
     ]
    }
   ],
   "source": [
    "theta=gradient_descent(X_train,y_train,theta,alpha,iterations)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,theta,mean,dev):\n",
    "    X=(X-mean)/dev\n",
    "    m_test=np.shape(X)[0]\n",
    "    X=np.hstack((np.ones((m_test,1)),X))\n",
    "    y_pred=sigmoid(X.dot(theta))>=0.5\n",
    "    return y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of my model=  55.08474576271186 %\n"
     ]
    }
   ],
   "source": [
    "y_pred=predict(X_test,theta,mean,dev)\n",
    "error=(y_pred==y_test)\n",
    "Merr=np.mean(error)*100\n",
    "print(\"accuracy of my model= \",Merr,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of my model=  54.23728813559322 %\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "regr = LogisticRegression()\n",
    "regr.fit(Xt,y_train)\n",
    "y_pred=regr.predict(Xt)\n",
    "y_pred=y_pred.reshape(np.shape(y_test))\n",
    "error=(y_pred==y_test)\n",
    "Merr=np.mean(error)*100\n",
    "print(\"accuracy of my model= \",Merr,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
